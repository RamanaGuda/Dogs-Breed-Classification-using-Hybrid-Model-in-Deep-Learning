{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YzQH_zh54BU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, AveragePooling2D, concatenate\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.metrics import classification_report, precision_score\n",
        "\n",
        "# Set the paths to your train, test, and validation data\n",
        "train_dir = '/content/drive/MyDrive/New folder (2)/train'\n",
        "test_dir = '/content/drive/MyDrive/test'\n",
        "validation_dir = '/content/drive/MyDrive/New folder (2)/validation'\n",
        "#hyperparameters\n",
        "epochs = 21\n",
        "batch_size = 16\n",
        "learning_rate = 0.0001\n",
        "\n",
        "\n",
        "# Preprocessing the images\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Custom CNN model\n",
        "cnn_input = Input(shape=(224, 224, 3))\n",
        "x = Conv2D(64, (3, 3), activation='relu')(cnn_input)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "# Add more convolutional and pooling layers as needed for your custom CNN\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "cnn_output = Dense(8, activation='softmax')(x)  # Change 14 to the number of classes for the CNN model\n",
        "cnn_model = Model(inputs=cnn_input, outputs=cnn_output)\n",
        "\n",
        "# GoogleNet (Inception) model\n",
        "inception_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "inception_output = inception_model(cnn_input)  # Output from the Inception model\n",
        "x = AveragePooling2D(pool_size=(5,5))(inception_output)\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "inception_output = Dense(14, activation='softmax')(x)  # Change 14 to the number of classes for the Inception model\n",
        "inception_model = Model(inputs=cnn_input, outputs=inception_output)\n",
        "\n",
        "# Hybrid model\n",
        "x = concatenate([cnn_output, inception_output], axis=-1)  # Concatenate the CNN and Inception outputs\n",
        "x = Dense(4096, activation='relu')(x)\n",
        "x = Dense(4096, activation='relu')(x)\n",
        "output_layer = Dense(14, activation='softmax')(x)  # Change 8 to the number of classes for the hybrid model\n",
        "model = Model(inputs=cnn_input, outputs=output_layer)\n",
        "\n",
        "optimizer = RMSprop(learning_rate=learning_rate)\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.n // batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=validation_generator.n // batch_size\n",
        ")\n",
        "\n",
        "# Plot training and validation loss graphs\n",
        "train_loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs_range = range(1, epochs + 1)\n",
        "\n",
        "plt.plot(epochs_range, train_loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle =False\n",
        ")\n",
        "test_loss, test_accuracy = model.evaluate(test_generator, steps=test_generator.n // batch_size)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)\n",
        "\n",
        "# Saving the model\n",
        "model.save('/content/drive/MyDrive/model_save/hybrid_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/model_save/hybrid_model.h5')\n",
        "# Load and preprocess the test image\n",
        "img_path = '/content/drive/MyDrive/New folder (2)/validation/Alaskan Malamute dog/Image_27.jpg_gaussian_blur.jpg'\n",
        "img = image.load_img(img_path, target_size=(224, 224))\n",
        "img = image.img_to_array(img)\n",
        "img = np.expand_dims(img, axis=0)\n",
        "img = img / 255.0  # Normalizing the image\n",
        "\n",
        "# Making prediction\n",
        "prediction = model.predict(img)\n",
        "predicted_class_index = np.argmax(prediction)\n",
        "predicted_probability = np.max(prediction)\n",
        "# give the class names\n",
        "class_names = ['Affenhuhua_dog', 'Afghan_Hound dog', 'Akita_DOG','Alaskan malamute_dog','American_Bulldog_dog','Auggie_dog','Beagle_dog','Belgian Tervuren_dog','Bichon Frise_dog','Bocker_dog','Borzoi_dog','Boxer_dog','Bugg_dog','Bulldog_dog']\n",
        "predicted_class_name = class_names[predicted_class_index]\n",
        "percentage = predicted_probability * 100\n",
        "# Printing the predicted class name and percentage\n",
        "print(f\"Predicted Class: {predicted_class_name} ({percentage:.2f}%)\")\n",
        "img = mpimg.imread(img_path)\n",
        "# Display the image\n",
        "plt.imshow(img)\n",
        "plt.axis('on')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kls09kE_6GmO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}